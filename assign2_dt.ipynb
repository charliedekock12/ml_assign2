{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charles de Kock - 26023830 - ML441 Assignment 2\n",
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "import json\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_og = pd.read_csv(os.path.dirname(os.getcwd()) + '/forestCover.csv', na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dt_preprocessing(df: pd.DataFrame):\n",
    "\n",
    "    df = df.drop(columns=['Aspect', 'Inclination', 'Water_Level', 'Observation_ID'])\n",
    "    df['Soil_Type1'] = df['Soil_Type1'].map({'positive': 1, 'negative': 0}).astype(np.int8)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = init_dt_preprocessing(data_og)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancing_transform(df: pd.DataFrame, target, strategy_over, strategy_under, r=None):\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    under = RandomUnderSampler(sampling_strategy=strategy_under, random_state=r)\n",
    "    X_under, y_under = under.fit_resample(X, y)\n",
    "\n",
    "    smote = SMOTE(sampling_strategy=strategy_over, random_state=r+1)\n",
    "    #smote_tomek = SMOTETomek(sampling_strategy=strategy_over, random_state=r) #consider using later, takes long tho\n",
    "    X_res, y_res = smote.fit_resample(X_under, y_under)\n",
    "\n",
    "    df_balanced = pd.DataFrame(X_res, columns=X.columns)\n",
    "    df_balanced[target] = y_res\n",
    "\n",
    "    return df_balanced\n",
    "\n",
    "def balancing_transform_lean(X, y, strategy_over, strategy_under, r=None):\n",
    "\n",
    "    under = RandomUnderSampler(sampling_strategy=strategy_under, random_state=r)\n",
    "    X_under, y_under = under.fit_resample(X, y)\n",
    "\n",
    "    smote = SMOTE(sampling_strategy=strategy_over, random_state=r)\n",
    "    X_res, y_res = smote.fit_resample(X_under, y_under)\n",
    "\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = data_clean.drop(columns=['Cover_Type'])\n",
    "y_clean = data_clean['Cover_Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Cross fold setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=None)\n",
    "\n",
    "folds = []\n",
    "\n",
    "for train_index, val_index in skf.split(X_clean, y_clean):\n",
    "    X_train, X_val = X_clean.iloc[train_index], X_clean.iloc[val_index]\n",
    "    y_train, y_val = y_clean.iloc[train_index], y_clean.iloc[val_index]\n",
    "    folds.append({'Xt': X_train, 'Xv': X_val, 'yt': y_train, 'yv': y_val})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_fold(fold, strategies):\n",
    "    X, y = balancing_transform_lean(fold['Xt'], fold['yt'], strategies[1], strategies[0])\n",
    "    return {'Xt': X, 'Xv': fold['Xv'], 'yt': y, 'yv': fold['yv']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.08s/it]\n"
     ]
    }
   ],
   "source": [
    "strat_A = [{1: 50000, 2: 50000}, {3: 35000, 4: 20000, 5: 20000, 6: 30000, 7: 30000}]\n",
    "\n",
    "for i in tqdm(range(len(folds))):\n",
    "    folds[i] = oversample_fold(folds[i], strategies=strat_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(fold, fold_nr, param_id, params):\n",
    "    model = DecisionTreeClassifier(criterion=params['criterion'],\n",
    "                                   max_depth=params['max_depth'], \n",
    "                                   min_samples_leaf=params['min_samples_leaf'], \n",
    "                                   class_weight=params['class_weight'])\n",
    "    \n",
    "    model.fit(fold['Xt'], fold['yt'])\n",
    "    y_pred = model.predict(fold['Xv'])\n",
    "    f1_w = f1_score(fold['yv'], y_pred, average='weighted')\n",
    "    f1_m = f1_score(fold['yv'], y_pred, average='macro')\n",
    "    mcc = matthews_corrcoef(fold['yv'], y_pred)\n",
    "    \n",
    "    return {'fold_nr': fold_nr, 'param_id': param_id,'params': params, 'mcc': mcc, 'f1_weigthed': f1_w, 'f1_macro': f1_m}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_param_dicts(criteria, depths, min_samples_leaf, weight):\n",
    "    param_dicts = []\n",
    "    for c, d, ms, w in itertools.product(criteria, depths, min_samples_leaf, weight):\n",
    "            params = {\n",
    "                'criterion': c,\n",
    "                'max_depth': d, \n",
    "                'min_samples_leaf': ms, \n",
    "                'class_weight': w\n",
    "            }\n",
    "            param_dicts.append(params)\n",
    "    return param_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(param_grid, folds):\n",
    "    out = []\n",
    "    idx = 0\n",
    "    for i in tqdm(range(len(param_grid))):\n",
    "        for j in range(len(folds)):\n",
    "            out.append(eval_model(folds[j], j, i, param_grid[i]))\n",
    "            #print(\"Params:\", i, '\\nFold:', j, '\\n')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, file):\n",
    "    with open(file, \"w\") as f:\n",
    "        for d in results:\n",
    "            f.write(json.dumps(d) + \"\\n\")\n",
    "\n",
    "def load_results(file):\n",
    "    loaded_results = []\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            loaded_results.append(json.loads(line))\n",
    "    return loaded_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = generate_param_dicts(['gini', 'entropy'], np.linspace(20, 50, 12).astype(int), [1, 0.0002], [None, 'balanced'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [1:29:22<00:00, 55.85s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type int64 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[144]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m results_fine = grid_search(param_grid, folds)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43msave_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_fine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_fine_dt.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[138]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36msave_results\u001b[39m\u001b[34m(results, file)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         f.write(\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/json/__init__.py:231\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# cached encoder\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m skipkeys \u001b[38;5;129;01mand\u001b[39;00m ensure_ascii \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    228\u001b[39m     check_circular \u001b[38;5;129;01mand\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m separators \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    230\u001b[39m     default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sort_keys \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_encoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/json/encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/json/encoder.py:258\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    254\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    255\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, \u001b[38;5;28mself\u001b[39m.indent, floatstr,\n\u001b[32m    256\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    257\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type int64 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "results_fine = grid_search(param_grid, folds)\n",
    "save_results(results_fine, \"eval_fine_dt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results_fine:\n",
    "    result['params']['max_depth'] = int(result['params']['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(results_fine, \"eval_fine_dt_backup.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_results(data):\n",
    "    grouped_data = defaultdict(list)\n",
    "    for d in data:\n",
    "        grouped_data[d['param_id']].append(d)\n",
    "\n",
    "    summary_list = []\n",
    "    for param_id, group in grouped_data.items():\n",
    "        mcc_scores = [d['mcc'] for d in group]\n",
    "        f1_weigthed_scores = [d['f1_weigthed'] for d in group]\n",
    "        f1_macro_scores = [d['f1_macro'] for d in group]\n",
    "\n",
    "        summary = {\n",
    "            'param_id': param_id,\n",
    "            'params': group[0]['params'],\n",
    "            'mean_mcc': np.mean(mcc_scores),\n",
    "            'std_mcc': np.std(mcc_scores),\n",
    "            'mean_f1_weigthed': np.mean(f1_weigthed_scores),\n",
    "            'std_f1_weigthed': np.std(f1_weigthed_scores),\n",
    "            'mean_f1_macro': np.mean(f1_macro_scores),\n",
    "            'std_f1_macro': np.std(f1_macro_scores)\n",
    "        }\n",
    "        summary_list.append(summary)\n",
    "\n",
    "    return summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_results(results, key, show=False):\n",
    "    out = sorted(results, key=lambda x: x['mean_' + key], reverse=True)\n",
    "    if show == True:\n",
    "        for r in out:\n",
    "            print(f\"ID: {r['param_id']} Parameters: {r['params']} -> {key}: {r['mean_' + key]} ± {r['std_' + key]}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_fine_evals_mcc = sort_results(avg_results(results_fine), 'mcc', show=False)\n",
    "sorted_fine_evals_f1w = sort_results(avg_results(results_fine), 'f1_weigthed', show=False)\n",
    "sorted_fine_evals_f1m = sort_results(avg_results(results_fine), 'f1_macro', show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_evals(eval1, eval2, eval3):\n",
    "    out = defaultdict(int)\n",
    "    for i in range(len(eval1)):\n",
    "        out[str(eval1[i]['param_id'])] += (i + 1)\n",
    "    for i in range(len(eval2)):\n",
    "        out[str(eval2[i]['param_id'])] += (i + 1)\n",
    "    for i in range(len(eval3)):\n",
    "        out[str(eval3[i]['param_id'])] += (i + 1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('183', 8),\n",
       " ('182', 9),\n",
       " ('169', 10),\n",
       " ('168', 10),\n",
       " ('211', 11),\n",
       " ('197', 16),\n",
       " ('210', 21),\n",
       " ('196', 25),\n",
       " ('155', 26),\n",
       " ('154', 29),\n",
       " ('141', 34),\n",
       " ('140', 35),\n",
       " ('56', 41),\n",
       " ('84', 42),\n",
       " ('70', 46),\n",
       " ('98', 50),\n",
       " ('126', 51),\n",
       " ('42', 53),\n",
       " ('28', 57),\n",
       " ('127', 57),\n",
       " ('99', 62),\n",
       " ('85', 66),\n",
       " ('71', 69),\n",
       " ('57', 72),\n",
       " ('43', 76),\n",
       " ('14', 77),\n",
       " ('29', 82),\n",
       " ('112', 83),\n",
       " ('113', 87),\n",
       " ('15', 91),\n",
       " ('0', 92),\n",
       " ('1', 96),\n",
       " ('212', 99),\n",
       " ('198', 103),\n",
       " ('184', 107),\n",
       " ('142', 109),\n",
       " ('170', 109),\n",
       " ('128', 114),\n",
       " ('156', 115),\n",
       " ('100', 123),\n",
       " ('72', 126),\n",
       " ('58', 129),\n",
       " ('44', 130),\n",
       " ('86', 130),\n",
       " ('30', 133),\n",
       " ('114', 134),\n",
       " ('16', 139),\n",
       " ('2', 144),\n",
       " ('143', 147),\n",
       " ('171', 150),\n",
       " ('213', 153),\n",
       " ('199', 157),\n",
       " ('185', 158),\n",
       " ('157', 162),\n",
       " ('129', 165),\n",
       " ('115', 168),\n",
       " ('87', 172),\n",
       " ('101', 175),\n",
       " ('73', 175),\n",
       " ('59', 180),\n",
       " ('45', 183),\n",
       " ('31', 186),\n",
       " ('17', 189),\n",
       " ('3', 200),\n",
       " ('18', 203),\n",
       " ('32', 206),\n",
       " ('88', 209),\n",
       " ('144', 210),\n",
       " ('46', 212),\n",
       " ('200', 214),\n",
       " ('74', 215),\n",
       " ('186', 215),\n",
       " ('60', 218),\n",
       " ('214', 219),\n",
       " ('102', 221),\n",
       " ('158', 222),\n",
       " ('4', 224),\n",
       " ('172', 226),\n",
       " ('130', 227),\n",
       " ('116', 231),\n",
       " ('6', 266),\n",
       " ('33', 267),\n",
       " ('20', 269),\n",
       " ('47', 270),\n",
       " ('34', 272),\n",
       " ('61', 273),\n",
       " ('173', 274),\n",
       " ('48', 275),\n",
       " ('75', 276),\n",
       " ('187', 277),\n",
       " ('62', 278),\n",
       " ('89', 279),\n",
       " ('215', 280),\n",
       " ('76', 281),\n",
       " ('103', 282),\n",
       " ('145', 283),\n",
       " ('90', 284),\n",
       " ('19', 285),\n",
       " ('201', 287),\n",
       " ('104', 287),\n",
       " ('131', 290),\n",
       " ('117', 291),\n",
       " ('159', 294),\n",
       " ('5', 304),\n",
       " ('118', 307),\n",
       " ('132', 310),\n",
       " ('146', 313),\n",
       " ('160', 316),\n",
       " ('174', 319),\n",
       " ('188', 322),\n",
       " ('202', 325),\n",
       " ('216', 328),\n",
       " ('119', 354),\n",
       " ('133', 357),\n",
       " ('147', 360),\n",
       " ('161', 363),\n",
       " ('8', 363),\n",
       " ('175', 366),\n",
       " ('22', 366),\n",
       " ('189', 369),\n",
       " ('36', 369),\n",
       " ('21', 371),\n",
       " ('203', 372),\n",
       " ('50', 372),\n",
       " ('35', 374),\n",
       " ('217', 375),\n",
       " ('64', 375),\n",
       " ('49', 377),\n",
       " ('78', 378),\n",
       " ('63', 380),\n",
       " ('92', 381),\n",
       " ('77', 383),\n",
       " ('106', 384),\n",
       " ('91', 386),\n",
       " ('105', 389),\n",
       " ('7', 400),\n",
       " ('120', 411),\n",
       " ('134', 414),\n",
       " ('148', 417),\n",
       " ('162', 420),\n",
       " ('176', 423),\n",
       " ('190', 426),\n",
       " ('204', 429),\n",
       " ('218', 432),\n",
       " ('10', 443),\n",
       " ('24', 446),\n",
       " ('38', 449),\n",
       " ('52', 452),\n",
       " ('66', 455),\n",
       " ('80', 458),\n",
       " ('121', 460),\n",
       " ('94', 461),\n",
       " ('135', 463),\n",
       " ('108', 464),\n",
       " ('149', 466),\n",
       " ('9', 467),\n",
       " ('163', 469),\n",
       " ('177', 472),\n",
       " ('191', 475),\n",
       " ('23', 478),\n",
       " ('205', 478),\n",
       " ('37', 481),\n",
       " ('219', 481),\n",
       " ('51', 484),\n",
       " ('65', 487),\n",
       " ('79', 490),\n",
       " ('93', 493),\n",
       " ('107', 496),\n",
       " ('122', 507),\n",
       " ('136', 510),\n",
       " ('150', 513),\n",
       " ('164', 516),\n",
       " ('178', 519),\n",
       " ('192', 522),\n",
       " ('206', 525),\n",
       " ('220', 528),\n",
       " ('12', 531),\n",
       " ('26', 534),\n",
       " ('40', 537),\n",
       " ('54', 540),\n",
       " ('68', 543),\n",
       " ('82', 546),\n",
       " ('96', 549),\n",
       " ('110', 552),\n",
       " ('123', 555),\n",
       " ('137', 558),\n",
       " ('151', 561),\n",
       " ('165', 564),\n",
       " ('179', 567),\n",
       " ('193', 570),\n",
       " ('207', 573),\n",
       " ('221', 576),\n",
       " ('11', 587),\n",
       " ('25', 590),\n",
       " ('39', 593),\n",
       " ('124', 595),\n",
       " ('53', 596),\n",
       " ('138', 598),\n",
       " ('67', 599),\n",
       " ('152', 601),\n",
       " ('81', 602),\n",
       " ('166', 604),\n",
       " ('95', 605),\n",
       " ('180', 607),\n",
       " ('109', 608),\n",
       " ('194', 610),\n",
       " ('208', 613),\n",
       " ('222', 616),\n",
       " ('13', 627),\n",
       " ('27', 630),\n",
       " ('41', 633),\n",
       " ('55', 636),\n",
       " ('69', 639),\n",
       " ('83', 642),\n",
       " ('97', 645),\n",
       " ('111', 648),\n",
       " ('125', 651),\n",
       " ('139', 654),\n",
       " ('153', 657),\n",
       " ('167', 660),\n",
       " ('181', 663),\n",
       " ('195', 666),\n",
       " ('209', 669),\n",
       " ('223', 672)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ranks = combine_evals(sorted_fine_evals_mcc, sorted_fine_evals_f1w, sorted_fine_evals_f1m)\n",
    "sorted(combined_ranks.items(), key=lambda item: item[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ID(results , id):\n",
    "    return [d for d in results if d.get('param_id') == id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = find_ID(results_fine, 183)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fold_nr': 0,\n",
       "  'param_id': 183,\n",
       "  'params': {'criterion': 'entropy',\n",
       "   'max_depth': 37,\n",
       "   'min_samples_leaf': 1,\n",
       "   'class_weight': 'balanced'},\n",
       "  'mcc': 0.8325450423298141,\n",
       "  'f1_weigthed': 0.8944733353057686,\n",
       "  'f1_macro': 0.8644708657374887},\n",
       " {'fold_nr': 1,\n",
       "  'param_id': 183,\n",
       "  'params': {'criterion': 'entropy',\n",
       "   'max_depth': 37,\n",
       "   'min_samples_leaf': 1,\n",
       "   'class_weight': 'balanced'},\n",
       "  'mcc': 0.829249286534213,\n",
       "  'f1_weigthed': 0.8922611004328261,\n",
       "  'f1_macro': 0.8665297012516382},\n",
       " {'fold_nr': 2,\n",
       "  'param_id': 183,\n",
       "  'params': {'criterion': 'entropy',\n",
       "   'max_depth': 37,\n",
       "   'min_samples_leaf': 1,\n",
       "   'class_weight': 'balanced'},\n",
       "  'mcc': 0.832406632431436,\n",
       "  'f1_weigthed': 0.894402657715297,\n",
       "  'f1_macro': 0.8631082114259925},\n",
       " {'fold_nr': 3,\n",
       "  'param_id': 183,\n",
       "  'params': {'criterion': 'entropy',\n",
       "   'max_depth': 37,\n",
       "   'min_samples_leaf': 1,\n",
       "   'class_weight': 'balanced'},\n",
       "  'mcc': 0.8309053420215569,\n",
       "  'f1_weigthed': 0.8933544982179393,\n",
       "  'f1_macro': 0.8668426779934579},\n",
       " {'fold_nr': 4,\n",
       "  'param_id': 183,\n",
       "  'params': {'criterion': 'entropy',\n",
       "   'max_depth': 37,\n",
       "   'min_samples_leaf': 1,\n",
       "   'class_weight': 'balanced'},\n",
       "  'mcc': 0.8302520526392586,\n",
       "  'f1_weigthed': 0.8930211741246665,\n",
       "  'f1_macro': 0.8612853164638349}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
